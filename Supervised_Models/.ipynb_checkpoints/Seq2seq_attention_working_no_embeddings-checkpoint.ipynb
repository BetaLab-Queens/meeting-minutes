{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention seq2seq without using GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from attention import AttentionLayer\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"..\\\\Data\\\\model_training\\\\100000_samples_Reviews.csv\")\n",
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, exclude_encodings=\"lxml\").text # removes html/xml taggs\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9429609634551495\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 66.13385464581417\n",
      "Total Coverage of rare words: 2.8008604605634035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8836"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 77.98577703409329\n",
      "Total Coverage of rare words: 5.1513542219861925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2106"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46694, 46694)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8836"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      883600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    210600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 2106)   1265706     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,945,006\n",
      "Trainable params: 4,945,006\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45550 samples, validate on 5036 samples\n",
      "Epoch 1/2\n",
      "45550/45550 [==============================] - 884s 19ms/sample - loss: 2.5381 - val_loss: 2.4232\n",
      "Epoch 2/2\n",
      "45550/45550 [==============================] - 851s 19ms/sample - loss: 2.3755 - val_loss: 2.2974\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1) #,patience=2) # use patience when actually building the model\n",
    "history=model.fit([x_tr,y_tr[:,:-1]], \n",
    "                  y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:],\n",
    "                  epochs=2,callbacks=[es],\n",
    "                  batch_size=128,\n",
    "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    print('e_out:', e_out[0][0][0])\n",
    "    print('e_h:', e_h[0][0])\n",
    "    print('e_c:', e_c[0][0])\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "    # works fine\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "#         print(\"output_tokens:\", output_tokens)\n",
    "    \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "#         print(sampled_token_index)\n",
    "#         if sampled_token_index != 0: # loops here too many times, shouldn't have an index of 0, but consistently does. \n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        print('sample token:', sampled_token)\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok' or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: peanut butter indeed delicious creamy use cookies eat sandwiches apples tastes close shelled peanuts get jar sure oils slight aftertaste though \n",
      "Original summary: delicious \n",
      "\n",
      "e_out: 0.023713607\n",
      "e_h: -0.011991915\n",
      "e_c: -0.17236792\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: chihuahua pomeranian get excited bring teenie dental chews meal hope always stock buy frequently seems help reduce tartar teeth exceptionally high protein unlike treats \n",
      "Original summary: my dogs go crazy for greenies \n",
      "\n",
      "e_out: 0.06416201\n",
      "e_h: 0.012823787\n",
      "e_c: 0.10182106\n",
      "sample token: great\n",
      "sample token: product\n",
      "sample token: eostok\n",
      "Predicted summary:  great product\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: first experience brand cut gum small bone inside one snacks many beef stick products never found bone inside buy company dont bite hard first chews \n",
      "Original summary: bone \n",
      "\n",
      "e_out: -0.008148952\n",
      "e_h: -0.01710472\n",
      "e_c: -0.14280887\n",
      "sample token: great\n",
      "sample token: product\n",
      "sample token: eostok\n",
      "Predicted summary:  great product\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: delicious crackers stay nice crispy even humid weather unfortunately particular packaging seems prone breaking transit still taste good think order different packaging seem transport better \n",
      "Original summary: excelent flavor but many crackers broken \n",
      "\n",
      "e_out: 0.015889699\n",
      "e_h: -0.016782017\n",
      "e_c: -0.17393188\n",
      "sample token: not\n",
      "sample token: good\n",
      "sample token: eostok\n",
      "Predicted summary:  not good\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: like soy milk definitely cost effective great long term storage great recipes family like drink reconstituted however even cold say taste use cooking baking \n",
      "Original summary: soy milk \n",
      "\n",
      "e_out: -0.014582304\n",
      "e_h: -0.009906855\n",
      "e_c: -0.13114263\n",
      "sample token: great\n",
      "sample token: product\n",
      "sample token: eostok\n",
      "Predicted summary:  great product\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: awesome product finally wheat gluten dairy allergy enjoy bread easy make tastes great \n",
      "Original summary: awesome \n",
      "\n",
      "e_out: 0.027441109\n",
      "e_h: 0.0021326763\n",
      "e_c: 0.05678127\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: cats love eat cat foods used switching new foods tricky problem loved food even cat never eats canned food dug food tasty looking great aroma good stuff \n",
      "Original summary: great assortment aroma cats love it \n",
      "\n",
      "e_out: -0.06102475\n",
      "e_h: -0.16528216\n",
      "e_c: -1.9989375\n",
      "sample token: my\n",
      "sample token: cat\n",
      "sample token: loves\n",
      "sample token: these\n",
      "sample token: eostok\n",
      "Predicted summary:  my cat loves these\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: hard stay wonderful cookies right amount chocolate chips texture melt mouth good \n",
      "Original summary: cookies \n",
      "\n",
      "e_out: 0.00062597205\n",
      "e_h: 0.0017959843\n",
      "e_c: 0.05147712\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: treat red persian eat large eat everything sight cats home treat one put something else cats leave alone wait one big trouble ever discontinued \n",
      "Original summary: cat treats \n",
      "\n",
      "e_out: 0.034909707\n",
      "e_h: -0.12818567\n",
      "e_c: -1.1106871\n",
      "sample token: my\n",
      "sample token: cat\n",
      "sample token: loves\n",
      "sample token: these\n",
      "sample token: eostok\n",
      "Predicted summary:  my cat loves these\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: check local grocery better price oil good overpriced amazon \n",
      "Original summary: kind of expensive \n",
      "\n",
      "e_out: -0.016335968\n",
      "e_h: 0.0020777571\n",
      "e_c: 0.06632402\n",
      "sample token: great\n",
      "sample token: product\n",
      "sample token: eostok\n",
      "Predicted summary:  great product\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: makes great alternative times want something refreshing beer perfect size sugar chemical sweetener preservatives filtered carbonated water mg sodium \n",
      "Original summary: club soda \n",
      "\n",
      "e_out: 0.01822645\n",
      "e_h: 0.00045495317\n",
      "e_c: 0.010468787\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: found cheese snacks terrible smell like dog treats taste like would imagine dog treats taste like whole heartedly avoid snacks \n",
      "Original summary: just awful \n",
      "\n",
      "e_out: -0.0050491\n",
      "e_h: 0.031200102\n",
      "e_c: 0.33110133\n",
      "sample token: my\n",
      "sample token: dog\n",
      "sample token: loves\n",
      "sample token: these\n",
      "sample token: eostok\n",
      "Predicted summary:  my dog loves these\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: time organic food good good tasting organic mac cheese albeit still processed food way get better food make organic batch scratch \n",
      "Original summary: good organic \n",
      "\n",
      "e_out: 0.010957775\n",
      "e_h: -0.016898695\n",
      "e_c: -0.22940646\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: tried product florida vacation tasty slightly sweet nice coconut flavor wonderfully refreshing loved however bottles bottle definitly good deal \n",
      "Original summary: great product but this price \n",
      "\n",
      "e_out: 0.018782716\n",
      "e_h: 0.0017887942\n",
      "e_c: 0.04603915\n",
      "sample token: great\n",
      "sample token: product\n",
      "sample token: eostok\n",
      "Predicted summary:  great product\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: love sauce sweet molasses tiny kick heat use make hawaiian chicken pork time never authentic jamaican jerk cannot vouch whole family loves one \n",
      "Original summary: maybe not authentic but it is yummy \n",
      "\n",
      "e_out: 0.023098597\n",
      "e_h: -0.005475519\n",
      "e_c: -0.08341542\n",
      "sample token: good\n",
      "sample token: stuff\n",
      "sample token: eostok\n",
      "Predicted summary:  good stuff\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: usually pomegranate fan gave try anyway favorite flavor would tell anyone try today \n",
      "Original summary: good stuff \n",
      "\n",
      "e_out: -0.005675828\n",
      "e_h: 0.0022329185\n",
      "e_c: 0.06783488\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: cat likes food much overpriced ripoff garbage vets sell even shipping cheaper delivered right door one less run \n",
      "Original summary: good food at better price \n",
      "\n",
      "e_out: -0.068490505\n",
      "e_h: -0.0055020056\n",
      "e_c: -0.08952033\n",
      "sample token: cat\n",
      "sample token: food\n",
      "sample token: eostok\n",
      "Predicted summary:  cat food\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: best olive oil ever tasted tasted lot olive oil life forget making vinaigrette salad use straight smooth buttery tasting drizzle anything disappointed cook bake \n",
      "Original summary: like butter \n",
      "\n",
      "e_out: 0.041135557\n",
      "e_h: -0.0072109275\n",
      "e_c: -0.09774795\n",
      "sample token: great\n",
      "sample token: product\n",
      "sample token: eostok\n",
      "Predicted summary:  great product\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: pretty good healthy granola product fact healthy healthier others although could used little chocolate taste also smaller granola bars good product hard recommend better \n",
      "Original summary: pretty good not the best \n",
      "\n",
      "e_out: -0.050950423\n",
      "e_h: -0.032690857\n",
      "e_c: -0.38788986\n",
      "sample token: great\n",
      "sample token: eostok\n",
      "Predicted summary:  great\n",
      "________________________________________________________\n",
      "\n",
      "\n",
      "Review: young cat went kidney failure regarding food water intake absolutely loves food looks every morning amazon makes getting breeze appreciate reviews led product really really likes \n",
      "Original summary: could not be more pleased \n",
      "\n",
      "e_out: -0.009092981\n",
      "e_h: -0.0535988\n",
      "e_c: -0.3801823\n",
      "sample token: my\n",
      "sample token: cat\n",
      "sample token: loves\n",
      "sample token: these\n",
      "sample token: eostok\n",
      "Predicted summary:  my cat loves these\n",
      "________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print()\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46694"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_tr_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
